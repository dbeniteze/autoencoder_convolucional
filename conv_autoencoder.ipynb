{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "conv_autoencoder.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyP/eOped0m8aw84Q9+LlyFc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dbeniteze/autoencoder_convolucional/blob/master/conv_autoencoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvCGvOKYgDVf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "7dcd0559-95c7-49ab-b507-d5e3989069f2"
      },
      "source": [
        "!pip3 install keras==2.3.1\n",
        "\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras==2.3.1 in /usr/local/lib/python3.6/dist-packages (2.3.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (3.13)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.0.8)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.17.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (2.8.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.12.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.1.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.4.1)\n",
            "TensorFlow 2.x selected.\n",
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoJIAQUigGRf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Larger CNN for the MNIST Dataset\n",
        "from keras import backend as K\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout, Reshape\n",
        "from keras.layers import Flatten, BatchNormalization\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "# load data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "# reshape to be [samples][width][height][channels]\n",
        "X_train = X_train.reshape((X_train.shape[0], 28, 28, 1)).astype('float32')\n",
        "X_test = X_test.reshape((X_test.shape[0], 28, 28, 1)).astype('float32')\n",
        "# normalize inputs from 0-255 to 0-1\n",
        "X_train = X_train / 255\n",
        "X_test = X_test / 255\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E19oJS3_gc8W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "outputId": "20709896-3935-40dc-ce6f-3291e8ac2bc4"
      },
      "source": [
        "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
        "from keras.models import Model\n",
        "from keras import backend as K\n",
        "\n",
        "input_img = Input(shape=(28, 28, 1))  # adapt this if using `channels_first` image data format\n",
        "\n",
        "x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "# at this point the representation is (4, 4, 8) i.e. 128-dimensional\n",
        "\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(16, (3, 3), activation='relu')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "autoencoder = Model(input_img, decoded)\n",
        "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
        "autoencoder.summary()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 28, 28, 16)        160       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 14, 14, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 14, 14, 8)         1160      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 7, 7, 8)           0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 7, 7, 8)           584       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 4, 4, 8)           0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 4, 4, 8)           584       \n",
            "_________________________________________________________________\n",
            "up_sampling2d_4 (UpSampling2 (None, 8, 8, 8)           0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 8, 8, 8)           584       \n",
            "_________________________________________________________________\n",
            "up_sampling2d_5 (UpSampling2 (None, 16, 16, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 14, 14, 16)        1168      \n",
            "_________________________________________________________________\n",
            "up_sampling2d_6 (UpSampling2 (None, 28, 28, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 28, 28, 1)         145       \n",
            "=================================================================\n",
            "Total params: 4,385\n",
            "Trainable params: 4,385\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gq3w3i8IgnWQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "464c88f9-0c4e-4c87-d8e2-705d3391dc73"
      },
      "source": [
        "\n",
        "autoencoder.fit(X_train, X_train,\n",
        "                epochs=50,\n",
        "                batch_size=128,\n",
        "                shuffle=True,\n",
        "                validation_data=(X_test, X_test))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "60000/60000 [==============================] - 10s 171us/step - loss: 0.2059 - val_loss: 0.1651\n",
            "Epoch 2/50\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.1552 - val_loss: 0.1431\n",
            "Epoch 3/50\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.1424 - val_loss: 0.1369\n",
            "Epoch 4/50\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.1346 - val_loss: 0.1308\n",
            "Epoch 5/50\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.1292 - val_loss: 0.1255\n",
            "Epoch 6/50\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.1258 - val_loss: 0.1220\n",
            "Epoch 7/50\n",
            "60000/60000 [==============================] - 4s 58us/step - loss: 0.1232 - val_loss: 0.1197\n",
            "Epoch 8/50\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.1211 - val_loss: 0.1170\n",
            "Epoch 9/50\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.1192 - val_loss: 0.1167\n",
            "Epoch 10/50\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.1176 - val_loss: 0.1138\n",
            "Epoch 11/50\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.1162 - val_loss: 0.1141\n",
            "Epoch 12/50\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.1151 - val_loss: 0.1115\n",
            "Epoch 13/50\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.1142 - val_loss: 0.1107\n",
            "Epoch 14/50\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.1128 - val_loss: 0.1122\n",
            "Epoch 15/50\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.1123 - val_loss: 0.1080\n",
            "Epoch 16/50\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.1111 - val_loss: 0.1103\n",
            "Epoch 17/50\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.1105 - val_loss: 0.1094\n",
            "Epoch 18/50\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.1100 - val_loss: 0.1073\n",
            "Epoch 19/50\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.1095 - val_loss: 0.1074\n",
            "Epoch 20/50\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.1089 - val_loss: 0.1054\n",
            "Epoch 21/50\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.1083 - val_loss: 0.1035\n",
            "Epoch 22/50\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.1080 - val_loss: 0.1061\n",
            "Epoch 23/50\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.1075 - val_loss: 0.1064\n",
            "Epoch 24/50\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.1072 - val_loss: 0.1057\n",
            "Epoch 25/50\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.1068 - val_loss: 0.1049\n",
            "Epoch 26/50\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.1063 - val_loss: 0.1027\n",
            "Epoch 27/50\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.1061 - val_loss: 0.1040\n",
            "Epoch 28/50\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.1059 - val_loss: 0.1063\n",
            "Epoch 29/50\n",
            "60000/60000 [==============================] - 4s 58us/step - loss: 0.1058 - val_loss: 0.1019\n",
            "Epoch 30/50\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.1054 - val_loss: 0.1038\n",
            "Epoch 31/50\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.1052 - val_loss: 0.1067\n",
            "Epoch 32/50\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.1050 - val_loss: 0.1039\n",
            "Epoch 33/50\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.1045 - val_loss: 0.1050\n",
            "Epoch 34/50\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.1044 - val_loss: 0.1007\n",
            "Epoch 35/50\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.1043 - val_loss: 0.1069\n",
            "Epoch 36/50\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.1040 - val_loss: 0.1017\n",
            "Epoch 37/50\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.1038 - val_loss: 0.1028\n",
            "Epoch 38/50\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.1039 - val_loss: 0.1021\n",
            "Epoch 39/50\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.1037 - val_loss: 0.1017\n",
            "Epoch 40/50\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.1035 - val_loss: 0.1041\n",
            "Epoch 41/50\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.1032 - val_loss: 0.1015\n",
            "Epoch 42/50\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.1032 - val_loss: 0.1021\n",
            "Epoch 43/50\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.1031 - val_loss: 0.1011\n",
            "Epoch 44/50\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.1031 - val_loss: 0.1013\n",
            "Epoch 45/50\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.1028 - val_loss: 0.1014\n",
            "Epoch 46/50\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.1028 - val_loss: 0.1019\n",
            "Epoch 47/50\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.1027 - val_loss: 0.1015\n",
            "Epoch 48/50\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.1020 - val_loss: 0.0999\n",
            "Epoch 49/50\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.1021 - val_loss: 0.1004\n",
            "Epoch 50/50\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.1021 - val_loss: 0.0997\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f8ab051aef0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsVytqEOg-Cd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "outputId": "c750d661-0ccc-4f74-bbff-b02e15d77bd4"
      },
      "source": [
        "#visualizacion de la decodificacion\n",
        "decoded_imgs = autoencoder.predict(X_test)\n",
        "\n",
        "n = 7\n",
        "plt.figure(figsize=(14, 4))\n",
        "for i in range(n):\n",
        "    i = i + 1\n",
        "    # display original\n",
        "    ax = plt.subplot(2, n, i)\n",
        "    plt.imshow(X_test[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # display reconstruction\n",
        "    ax = plt.subplot(2, n, i+n)\n",
        "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAx8AAADnCAYAAAB/jetMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
            "text/plain": [
              "<Figure size 1008x288 with 14 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}