{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "conv_autoencoder.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOoCCVyJmX4ST7EgwHvxCh7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dbeniteze/autoencoder_convolucional/blob/master/conv_autoencoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvCGvOKYgDVf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "7dcd0559-95c7-49ab-b507-d5e3989069f2"
      },
      "source": [
        "!pip3 install keras==2.3.1\n",
        "\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras==2.3.1 in /usr/local/lib/python3.6/dist-packages (2.3.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (3.13)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.0.8)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.17.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (2.8.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.12.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.1.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.4.1)\n",
            "TensorFlow 2.x selected.\n",
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoJIAQUigGRf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Larger CNN for the MNIST Dataset\n",
        "from keras import backend as K\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout, Reshape\n",
        "from keras.layers import Flatten, BatchNormalization\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "# load data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "# reshape to be [samples][width][height][channels]\n",
        "X_train = X_train.reshape((X_train.shape[0], 28, 28, 1)).astype('float32')\n",
        "X_test = X_test.reshape((X_test.shape[0], 28, 28, 1)).astype('float32')\n",
        "# normalize inputs from 0-255 to 0-1\n",
        "X_train = X_train / 255\n",
        "X_test = X_test / 255\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E19oJS3_gc8W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "outputId": "d6d5b397-acc8-4f61-d783-6df4e04c651d"
      },
      "source": [
        "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
        "from keras.models import Model\n",
        "from keras import backend as K\n",
        "\n",
        "input_img = Input(shape=(28, 28, 1))  # adapt this if using `channels_first` image data format\n",
        "LF = (5,5)\n",
        "x = Conv2D(16, LF, activation='relu', padding='same')(input_img)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(8, LF, activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(8, LF, activation='relu', padding='same')(x)\n",
        "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "# at this point the representation is (4, 4, 8) i.e. 128-dimensional\n",
        "\n",
        "x = Conv2D(8, (3,3), activation='relu', padding='same')(encoded)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(8, (3,3), activation='relu', padding='same')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(16, (3,3), activation='relu')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "decoded = Conv2D(1, (3,3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "autoencoder = Model(input_img, decoded)\n",
        "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
        "autoencoder.summary()"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_10 (InputLayer)        (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_64 (Conv2D)           (None, 28, 28, 16)        416       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_28 (MaxPooling (None, 14, 14, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_65 (Conv2D)           (None, 14, 14, 8)         3208      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_29 (MaxPooling (None, 7, 7, 8)           0         \n",
            "_________________________________________________________________\n",
            "conv2d_66 (Conv2D)           (None, 7, 7, 8)           1608      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_30 (MaxPooling (None, 4, 4, 8)           0         \n",
            "_________________________________________________________________\n",
            "conv2d_67 (Conv2D)           (None, 4, 4, 8)           584       \n",
            "_________________________________________________________________\n",
            "up_sampling2d_28 (UpSampling (None, 8, 8, 8)           0         \n",
            "_________________________________________________________________\n",
            "conv2d_68 (Conv2D)           (None, 8, 8, 8)           584       \n",
            "_________________________________________________________________\n",
            "up_sampling2d_29 (UpSampling (None, 16, 16, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_69 (Conv2D)           (None, 14, 14, 16)        1168      \n",
            "_________________________________________________________________\n",
            "up_sampling2d_30 (UpSampling (None, 28, 28, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_70 (Conv2D)           (None, 28, 28, 1)         145       \n",
            "=================================================================\n",
            "Total params: 7,713\n",
            "Trainable params: 7,713\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gq3w3i8IgnWQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "57fec858-42c6-47fc-d0d5-1f0a3f5e9539"
      },
      "source": [
        "\n",
        "autoencoder.fit(X_train, X_train,\n",
        "                epochs=50,\n",
        "                batch_size=128,\n",
        "                shuffle=True,\n",
        "                validation_data=(X_test, X_test))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "60000/60000 [==============================] - 4s 69us/step - loss: 0.2169 - val_loss: 0.1678\n",
            "Epoch 2/50\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 0.1580 - val_loss: 0.1479\n",
            "Epoch 3/50\n",
            "60000/60000 [==============================] - 4s 62us/step - loss: 0.1430 - val_loss: 0.1362\n",
            "Epoch 4/50\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 0.1345 - val_loss: 0.1303\n",
            "Epoch 5/50\n",
            "60000/60000 [==============================] - 4s 62us/step - loss: 0.1288 - val_loss: 0.1232\n",
            "Epoch 6/50\n",
            "60000/60000 [==============================] - 4s 62us/step - loss: 0.1247 - val_loss: 0.1247\n",
            "Epoch 7/50\n",
            "60000/60000 [==============================] - 4s 62us/step - loss: 0.1218 - val_loss: 0.1217\n",
            "Epoch 8/50\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 0.1191 - val_loss: 0.1163\n",
            "Epoch 9/50\n",
            "60000/60000 [==============================] - 4s 62us/step - loss: 0.1169 - val_loss: 0.1185\n",
            "Epoch 10/50\n",
            "60000/60000 [==============================] - 4s 62us/step - loss: 0.1152 - val_loss: 0.1217\n",
            "Epoch 11/50\n",
            "60000/60000 [==============================] - 4s 62us/step - loss: 0.1135 - val_loss: 0.1139\n",
            "Epoch 12/50\n",
            "60000/60000 [==============================] - 4s 62us/step - loss: 0.1117 - val_loss: 0.1137\n",
            "Epoch 13/50\n",
            "60000/60000 [==============================] - 4s 62us/step - loss: 0.1104 - val_loss: 0.1121\n",
            "Epoch 14/50\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 0.1094 - val_loss: 0.1079\n",
            "Epoch 15/50\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 0.1083 - val_loss: 0.1048\n",
            "Epoch 16/50\n",
            "60000/60000 [==============================] - 4s 62us/step - loss: 0.1072 - val_loss: 0.1100\n",
            "Epoch 17/50\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 0.1062 - val_loss: 0.1058\n",
            "Epoch 18/50\n",
            "60000/60000 [==============================] - 4s 62us/step - loss: 0.1053 - val_loss: 0.1021\n",
            "Epoch 19/50\n",
            "60000/60000 [==============================] - 4s 61us/step - loss: 0.1046 - val_loss: 0.1027\n",
            "Epoch 20/50\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 0.1039 - val_loss: 0.1020\n",
            "Epoch 21/50\n",
            "60000/60000 [==============================] - 4s 62us/step - loss: 0.1031 - val_loss: 0.1034\n",
            "Epoch 22/50\n",
            "60000/60000 [==============================] - 4s 62us/step - loss: 0.1024 - val_loss: 0.1006\n",
            "Epoch 23/50\n",
            "60000/60000 [==============================] - 4s 62us/step - loss: 0.1020 - val_loss: 0.1025\n",
            "Epoch 24/50\n",
            "60000/60000 [==============================] - 4s 62us/step - loss: 0.1017 - val_loss: 0.1052\n",
            "Epoch 25/50\n",
            "60000/60000 [==============================] - 4s 62us/step - loss: 0.1012 - val_loss: 0.1029\n",
            "Epoch 26/50\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 0.1007 - val_loss: 0.1006\n",
            "Epoch 27/50\n",
            "60000/60000 [==============================] - 4s 62us/step - loss: 0.1004 - val_loss: 0.1001\n",
            "Epoch 28/50\n",
            "60000/60000 [==============================] - 4s 62us/step - loss: 0.1000 - val_loss: 0.0975\n",
            "Epoch 29/50\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 0.0996 - val_loss: 0.0968\n",
            "Epoch 30/50\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 0.0990 - val_loss: 0.0980\n",
            "Epoch 31/50\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 0.0985 - val_loss: 0.0987\n",
            "Epoch 32/50\n",
            "60000/60000 [==============================] - 4s 62us/step - loss: 0.0982 - val_loss: 0.0970\n",
            "Epoch 33/50\n",
            "60000/60000 [==============================] - 4s 62us/step - loss: 0.0977 - val_loss: 0.0956\n",
            "Epoch 34/50\n",
            "60000/60000 [==============================] - 4s 62us/step - loss: 0.0977 - val_loss: 0.0957\n",
            "Epoch 35/50\n",
            "60000/60000 [==============================] - 4s 62us/step - loss: 0.0972 - val_loss: 0.0965\n",
            "Epoch 36/50\n",
            "60000/60000 [==============================] - 4s 64us/step - loss: 0.0973 - val_loss: 0.0955\n",
            "Epoch 37/50\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 0.0969 - val_loss: 0.0981\n",
            "Epoch 38/50\n",
            "60000/60000 [==============================] - 4s 62us/step - loss: 0.0967 - val_loss: 0.0948\n",
            "Epoch 39/50\n",
            "60000/60000 [==============================] - 4s 62us/step - loss: 0.0964 - val_loss: 0.0952\n",
            "Epoch 40/50\n",
            "60000/60000 [==============================] - 4s 62us/step - loss: 0.0961 - val_loss: 0.0937\n",
            "Epoch 41/50\n",
            "60000/60000 [==============================] - 4s 62us/step - loss: 0.0959 - val_loss: 0.0956\n",
            "Epoch 42/50\n",
            "60000/60000 [==============================] - 4s 62us/step - loss: 0.0957 - val_loss: 0.0944\n",
            "Epoch 43/50\n",
            "60000/60000 [==============================] - 4s 62us/step - loss: 0.0956 - val_loss: 0.0936\n",
            "Epoch 44/50\n",
            "60000/60000 [==============================] - 4s 61us/step - loss: 0.0955 - val_loss: 0.0954\n",
            "Epoch 45/50\n",
            "60000/60000 [==============================] - 4s 62us/step - loss: 0.0952 - val_loss: 0.0922\n",
            "Epoch 46/50\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 0.0947 - val_loss: 0.0940\n",
            "Epoch 47/50\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 0.0948 - val_loss: 0.0961\n",
            "Epoch 48/50\n",
            "60000/60000 [==============================] - 4s 62us/step - loss: 0.0943 - val_loss: 0.0960\n",
            "Epoch 49/50\n",
            "60000/60000 [==============================] - 4s 62us/step - loss: 0.0943 - val_loss: 0.0969\n",
            "Epoch 50/50\n",
            "60000/60000 [==============================] - 4s 62us/step - loss: 0.0944 - val_loss: 0.0938\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f8a920f1f98>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsVytqEOg-Cd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "outputId": "10a4ae89-cef5-4e46-f411-ea6d8a584f72"
      },
      "source": [
        "#visualizacion de la decodificacion\n",
        "decoded_imgs = autoencoder.predict(X_test)\n",
        "\n",
        "n = 7\n",
        "plt.figure(figsize=(14, 4))\n",
        "for i in range(n):\n",
        "    i = i + 1\n",
        "    # display original\n",
        "    ax = plt.subplot(2, n, i)\n",
        "    plt.imshow(X_test[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # display reconstruction\n",
        "    ax = plt.subplot(2, n, i+n)\n",
        "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAx8AAADnCAYAAAB/jetMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1008x288 with 14 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}