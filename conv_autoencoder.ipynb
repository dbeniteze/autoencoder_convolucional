{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "conv_autoencoder.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyP8rWqHgHxILVfMNted4fUU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dbeniteze/autoencoder_convolucional/blob/master/conv_autoencoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvCGvOKYgDVf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "7dcd0559-95c7-49ab-b507-d5e3989069f2"
      },
      "source": [
        "!pip3 install keras==2.3.1\n",
        "\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras==2.3.1 in /usr/local/lib/python3.6/dist-packages (2.3.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (3.13)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.0.8)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.17.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (2.8.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.12.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.1.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.4.1)\n",
            "TensorFlow 2.x selected.\n",
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoJIAQUigGRf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Larger CNN for the MNIST Dataset\n",
        "from keras import backend as K\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout, Reshape\n",
        "from keras.layers import Flatten, BatchNormalization\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, Conv2DTranspose\n",
        "from keras.models import Model\n",
        "from keras import backend as K\n",
        "# load data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "# reshape to be [samples][width][height][channels]\n",
        "X_train = X_train.reshape((X_train.shape[0], 28, 28, 1)).astype('float32')\n",
        "X_test = X_test.reshape((X_test.shape[0], 28, 28, 1)).astype('float32')\n",
        "# normalize inputs from 0-255 to 0-1\n",
        "X_train = X_train / 255\n",
        "X_test = X_test / 255\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E19oJS3_gc8W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# autoencoder simple con upsampling\n",
        "input_img = Input(shape=(28, 28, 1))  # adapt this if using `channels_first` image data format\n",
        "LF = (5,5)\n",
        "x = Conv2D(16, LF, activation='relu', padding='same')(input_img)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(8, LF, activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(8, LF, activation='relu', padding='same')(x)\n",
        "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "# at this point the representation is (4, 4, 8) i.e. 128-dimensional\n",
        "\n",
        "x = Conv2D(8, (3,3), activation='relu', padding='same')(encoded)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(8, (3,3), activation='relu', padding='same')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(16, (3,3), activation='relu')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "decoded = Conv2D(1, (3,3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "autoencoder = Model(input_img, decoded)\n",
        "autoencoder.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5cmI7s-zIMZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "91e96c91-67c9-4e47-b7b8-15d55ebe92ea"
      },
      "source": [
        "#autoencoder con Conv2DTranspose\n",
        "input_img = Input(shape=(28, 28, 1))  # adapt this if using `channels_first` image data format\n",
        "LF = (5,5)\n",
        "x = Conv2D(32, kernel_size=LF, activation='relu')(input_img)\n",
        "x = Conv2D(16, kernel_size=LF, activation='relu')(x)\n",
        "encoded = Conv2D(8, kernel_size=LF, activation='relu')(x)\n",
        "\n",
        "x = Conv2DTranspose(8, kernel_size=LF, activation='relu')(encoded)\n",
        "x = Conv2DTranspose(16, kernel_size=LF, activation='relu')(x)\n",
        "x = Conv2DTranspose(32, kernel_size=LF, activation='relu')(x)\n",
        "decoded = Conv2D(1, kernel_size=(3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "autoencoder = Model(input_img, decoded)\n",
        "autoencoder.summary()"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_17 (InputLayer)        (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_106 (Conv2D)          (None, 24, 24, 32)        832       \n",
            "_________________________________________________________________\n",
            "conv2d_107 (Conv2D)          (None, 20, 20, 16)        12816     \n",
            "_________________________________________________________________\n",
            "conv2d_108 (Conv2D)          (None, 16, 16, 8)         3208      \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_4 (Conv2DTr (None, 20, 20, 8)         1608      \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_5 (Conv2DTr (None, 24, 24, 16)        3216      \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_6 (Conv2DTr (None, 28, 28, 32)        12832     \n",
            "_________________________________________________________________\n",
            "conv2d_109 (Conv2D)          (None, 28, 28, 1)         289       \n",
            "=================================================================\n",
            "Total params: 34,801\n",
            "Trainable params: 34,801\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4-YSIs6zFa6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b3241ce5-5bd9-4c51-839c-258ce8f2b93d"
      },
      "source": [
        "def coeff_determination(y_true, y_pred):\n",
        "    SS_res =  K.sum(K.square( y_true-y_pred ))\n",
        "    SS_tot = K.sum(K.square( y_true - K.mean(y_true) ) )\n",
        "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )\n",
        "\n",
        "autoencoder.compile(optimizer='adadelta',  loss='mean_squared_error', metrics=[coeff_determination])\n",
        "\n",
        "autoencoder.fit(X_train, X_train,\n",
        "                epochs=50,\n",
        "                batch_size=128,\n",
        "                shuffle=True,\n",
        "                validation_data=(X_test, X_test))\n"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "60000/60000 [==============================] - 8s 130us/step - loss: 0.0281 - coeff_determination: 0.7044 - val_loss: 0.0074 - val_coeff_determination: 0.9220\n",
            "Epoch 2/50\n",
            "60000/60000 [==============================] - 7s 119us/step - loss: 0.0060 - coeff_determination: 0.9366 - val_loss: 0.0045 - val_coeff_determination: 0.9522\n",
            "Epoch 3/50\n",
            "60000/60000 [==============================] - 7s 120us/step - loss: 0.0041 - coeff_determination: 0.9565 - val_loss: 0.0048 - val_coeff_determination: 0.9499\n",
            "Epoch 4/50\n",
            "60000/60000 [==============================] - 7s 121us/step - loss: 0.0032 - coeff_determination: 0.9665 - val_loss: 0.0025 - val_coeff_determination: 0.9734\n",
            "Epoch 5/50\n",
            "60000/60000 [==============================] - 7s 120us/step - loss: 0.0026 - coeff_determination: 0.9723 - val_loss: 0.0024 - val_coeff_determination: 0.9745\n",
            "Epoch 6/50\n",
            "60000/60000 [==============================] - 7s 120us/step - loss: 0.0023 - coeff_determination: 0.9760 - val_loss: 0.0021 - val_coeff_determination: 0.9774\n",
            "Epoch 7/50\n",
            "60000/60000 [==============================] - 7s 121us/step - loss: 0.0020 - coeff_determination: 0.9787 - val_loss: 0.0020 - val_coeff_determination: 0.9792\n",
            "Epoch 8/50\n",
            "60000/60000 [==============================] - 7s 120us/step - loss: 0.0018 - coeff_determination: 0.9808 - val_loss: 0.0018 - val_coeff_determination: 0.9813\n",
            "Epoch 9/50\n",
            "60000/60000 [==============================] - 7s 121us/step - loss: 0.0017 - coeff_determination: 0.9824 - val_loss: 0.0015 - val_coeff_determination: 0.9844\n",
            "Epoch 10/50\n",
            "60000/60000 [==============================] - 7s 120us/step - loss: 0.0015 - coeff_determination: 0.9837 - val_loss: 0.0014 - val_coeff_determination: 0.9850\n",
            "Epoch 11/50\n",
            "60000/60000 [==============================] - 7s 120us/step - loss: 0.0014 - coeff_determination: 0.9848 - val_loss: 0.0014 - val_coeff_determination: 0.9855\n",
            "Epoch 12/50\n",
            "60000/60000 [==============================] - 7s 122us/step - loss: 0.0014 - coeff_determination: 0.9856 - val_loss: 0.0012 - val_coeff_determination: 0.9869\n",
            "Epoch 13/50\n",
            "60000/60000 [==============================] - 7s 121us/step - loss: 0.0013 - coeff_determination: 0.9865 - val_loss: 0.0011 - val_coeff_determination: 0.9880\n",
            "Epoch 14/50\n",
            "60000/60000 [==============================] - 7s 120us/step - loss: 0.0012 - coeff_determination: 0.9871 - val_loss: 0.0011 - val_coeff_determination: 0.9885\n",
            "Epoch 15/50\n",
            "60000/60000 [==============================] - 7s 121us/step - loss: 0.0012 - coeff_determination: 0.9877 - val_loss: 0.0011 - val_coeff_determination: 0.9886\n",
            "Epoch 16/50\n",
            "60000/60000 [==============================] - 7s 120us/step - loss: 0.0011 - coeff_determination: 0.9883 - val_loss: 0.0010 - val_coeff_determination: 0.9889\n",
            "Epoch 17/50\n",
            "60000/60000 [==============================] - 7s 121us/step - loss: 0.0011 - coeff_determination: 0.9887 - val_loss: 9.8813e-04 - val_coeff_determination: 0.9896\n",
            "Epoch 18/50\n",
            "60000/60000 [==============================] - 7s 119us/step - loss: 0.0010 - coeff_determination: 0.9891 - val_loss: 9.6817e-04 - val_coeff_determination: 0.9898\n",
            "Epoch 19/50\n",
            "60000/60000 [==============================] - 7s 120us/step - loss: 9.9654e-04 - coeff_determination: 0.9895 - val_loss: 0.0011 - val_coeff_determination: 0.9888\n",
            "Epoch 20/50\n",
            "60000/60000 [==============================] - 7s 120us/step - loss: 9.6867e-04 - coeff_determination: 0.9898 - val_loss: 9.6067e-04 - val_coeff_determination: 0.9899\n",
            "Epoch 21/50\n",
            "60000/60000 [==============================] - 7s 120us/step - loss: 9.2868e-04 - coeff_determination: 0.9902 - val_loss: 9.9969e-04 - val_coeff_determination: 0.9894\n",
            "Epoch 22/50\n",
            "60000/60000 [==============================] - 7s 121us/step - loss: 9.0726e-04 - coeff_determination: 0.9904 - val_loss: 9.1937e-04 - val_coeff_determination: 0.9903\n",
            "Epoch 23/50\n",
            "60000/60000 [==============================] - 7s 121us/step - loss: 8.7434e-04 - coeff_determination: 0.9908 - val_loss: 7.8296e-04 - val_coeff_determination: 0.9917\n",
            "Epoch 24/50\n",
            "60000/60000 [==============================] - 7s 123us/step - loss: 8.5680e-04 - coeff_determination: 0.9910 - val_loss: 8.5863e-04 - val_coeff_determination: 0.9909\n",
            "Epoch 25/50\n",
            "60000/60000 [==============================] - 7s 121us/step - loss: 8.3562e-04 - coeff_determination: 0.9912 - val_loss: 8.3831e-04 - val_coeff_determination: 0.9911\n",
            "Epoch 26/50\n",
            "60000/60000 [==============================] - 7s 122us/step - loss: 8.0764e-04 - coeff_determination: 0.9915 - val_loss: 8.1415e-04 - val_coeff_determination: 0.9914\n",
            "Epoch 27/50\n",
            "60000/60000 [==============================] - 7s 120us/step - loss: 7.9804e-04 - coeff_determination: 0.9916 - val_loss: 7.2886e-04 - val_coeff_determination: 0.9923\n",
            "Epoch 28/50\n",
            "60000/60000 [==============================] - 7s 122us/step - loss: 7.7576e-04 - coeff_determination: 0.9918 - val_loss: 7.2226e-04 - val_coeff_determination: 0.9924\n",
            "Epoch 29/50\n",
            "60000/60000 [==============================] - 7s 121us/step - loss: 7.5916e-04 - coeff_determination: 0.9920 - val_loss: 6.9783e-04 - val_coeff_determination: 0.9926\n",
            "Epoch 30/50\n",
            "60000/60000 [==============================] - 7s 119us/step - loss: 7.4178e-04 - coeff_determination: 0.9922 - val_loss: 7.5597e-04 - val_coeff_determination: 0.9920\n",
            "Epoch 31/50\n",
            "60000/60000 [==============================] - 7s 121us/step - loss: 7.3672e-04 - coeff_determination: 0.9922 - val_loss: 7.3795e-04 - val_coeff_determination: 0.9922\n",
            "Epoch 32/50\n",
            "60000/60000 [==============================] - 7s 120us/step - loss: 7.1493e-04 - coeff_determination: 0.9925 - val_loss: 6.9638e-04 - val_coeff_determination: 0.9926\n",
            "Epoch 33/50\n",
            "60000/60000 [==============================] - 7s 120us/step - loss: 6.9197e-04 - coeff_determination: 0.9927 - val_loss: 6.3870e-04 - val_coeff_determination: 0.9933\n",
            "Epoch 34/50\n",
            "60000/60000 [==============================] - 7s 122us/step - loss: 6.9356e-04 - coeff_determination: 0.9927 - val_loss: 6.6850e-04 - val_coeff_determination: 0.9930\n",
            "Epoch 35/50\n",
            "60000/60000 [==============================] - 7s 122us/step - loss: 6.7657e-04 - coeff_determination: 0.9929 - val_loss: 6.2974e-04 - val_coeff_determination: 0.9933\n",
            "Epoch 36/50\n",
            "60000/60000 [==============================] - 7s 122us/step - loss: 6.6257e-04 - coeff_determination: 0.9930 - val_loss: 6.5583e-04 - val_coeff_determination: 0.9931\n",
            "Epoch 37/50\n",
            "60000/60000 [==============================] - 7s 122us/step - loss: 6.5727e-04 - coeff_determination: 0.9931 - val_loss: 6.1435e-04 - val_coeff_determination: 0.9935\n",
            "Epoch 38/50\n",
            "60000/60000 [==============================] - 7s 122us/step - loss: 6.4583e-04 - coeff_determination: 0.9932 - val_loss: 5.8867e-04 - val_coeff_determination: 0.9938\n",
            "Epoch 39/50\n",
            "60000/60000 [==============================] - 7s 121us/step - loss: 6.3168e-04 - coeff_determination: 0.9933 - val_loss: 6.1025e-04 - val_coeff_determination: 0.9936\n",
            "Epoch 40/50\n",
            "60000/60000 [==============================] - 7s 122us/step - loss: 6.2400e-04 - coeff_determination: 0.9934 - val_loss: 7.1667e-04 - val_coeff_determination: 0.9924\n",
            "Epoch 41/50\n",
            "60000/60000 [==============================] - 7s 122us/step - loss: 6.1512e-04 - coeff_determination: 0.9935 - val_loss: 6.0568e-04 - val_coeff_determination: 0.9936\n",
            "Epoch 42/50\n",
            "60000/60000 [==============================] - 7s 121us/step - loss: 5.9926e-04 - coeff_determination: 0.9937 - val_loss: 5.6033e-04 - val_coeff_determination: 0.9941\n",
            "Epoch 43/50\n",
            "60000/60000 [==============================] - 7s 121us/step - loss: 5.9860e-04 - coeff_determination: 0.9937 - val_loss: 6.0118e-04 - val_coeff_determination: 0.9937\n",
            "Epoch 44/50\n",
            "60000/60000 [==============================] - 7s 120us/step - loss: 5.9433e-04 - coeff_determination: 0.9937 - val_loss: 5.9340e-04 - val_coeff_determination: 0.9937\n",
            "Epoch 45/50\n",
            "60000/60000 [==============================] - 7s 122us/step - loss: 5.7561e-04 - coeff_determination: 0.9939 - val_loss: 5.2651e-04 - val_coeff_determination: 0.9944\n",
            "Epoch 46/50\n",
            "60000/60000 [==============================] - 7s 120us/step - loss: 5.7015e-04 - coeff_determination: 0.9940 - val_loss: 5.5107e-04 - val_coeff_determination: 0.9942\n",
            "Epoch 47/50\n",
            "60000/60000 [==============================] - 7s 121us/step - loss: 5.6379e-04 - coeff_determination: 0.9941 - val_loss: 5.3043e-04 - val_coeff_determination: 0.9944\n",
            "Epoch 48/50\n",
            "60000/60000 [==============================] - 7s 122us/step - loss: 5.5738e-04 - coeff_determination: 0.9941 - val_loss: 5.0619e-04 - val_coeff_determination: 0.9947\n",
            "Epoch 49/50\n",
            "60000/60000 [==============================] - 7s 121us/step - loss: 5.5047e-04 - coeff_determination: 0.9942 - val_loss: 5.0534e-04 - val_coeff_determination: 0.9947\n",
            "Epoch 50/50\n",
            "60000/60000 [==============================] - 7s 122us/step - loss: 5.4082e-04 - coeff_determination: 0.9943 - val_loss: 4.8616e-04 - val_coeff_determination: 0.9949\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f8a7ece2b70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsVytqEOg-Cd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "outputId": "befdbc00-fcd9-4da7-9667-886568884595"
      },
      "source": [
        "#visualizacion de la decodificacion\n",
        "decoded_imgs = autoencoder.predict(X_test)\n",
        "\n",
        "n = 7\n",
        "plt.figure(figsize=(14, 4))\n",
        "for i in range(n):\n",
        "    i = i + 1\n",
        "    # display original\n",
        "    ax = plt.subplot(2, n, i)\n",
        "    plt.imshow(X_test[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # display reconstruction\n",
        "    ax = plt.subplot(2, n, i+n)\n",
        "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAx8AAADnCAYAAAB/jetMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAPCCwQcAAAAAL/4fp86xjXYtidUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1008x288 with 14 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}